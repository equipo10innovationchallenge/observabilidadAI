# AI Model Monitoring and Observability Dashboard
Overview

![Captura de pantalla 2024-12-20 a la(s) 6 52 53 p m](https://github.com/user-attachments/assets/52162a23-ac86-448b-9fdb-8a62536292c0)



This project provides a solution for monitoring and observing the performance of AI models deployed on Azure. The system collects key metrics, integrates user feedback, and visualizes insights through a dashboard interface. By leveraging various Azure services such as Azure OpenAI, Azure Machine Learning, Azure Blob Storage, Azure Monitor, and Application Insights, the system ensures continuous monitoring and optimization of model performance. The solution helps identify areas for improvement and provides actionable insights to enhance model efficiency and accuracy.

 

![isightlens](https://github.com/user-attachments/assets/1e81f3e6-6442-47c6-ada1-03ce046a000a)

## Demo

https://github.com/user-attachments/assets/63224451-229c-4841-8a16-e44de8167264

## Architecture

![diagram-current](https://github.com/user-attachments/assets/79f5a0f7-2291-4c96-a6fd-cc22c76f212a)

1. Chat Project Development
The solution leverages an Azure OpenAI's GPT-4 model, deployed through Azure AI Foundry. The model is configured and deployed in Azure Machine Learning (Azure ML) using Prompt Flow, ensuring seamless integration with the system and effective model interaction.


## 2. Data Collection and Storage
Logs and metrics generated by the deployed model are gathered and stored in Azure Blob Storage, configured as a Data Lake. This enables the system to securely store large volumes of log and performance data for analysis and later processing.

## 3. Monitoring and Analysis
Azure Monitor is used to track and manage the health and performance of the AI model. This includes real-time monitoring of system behavior, performance anomalies, and resource usage. Application Insights is used to provide deep insights into the collected data, enabling effective analysis and identification of trends for performance optimization.

## 4. Data Access
An API endpoint is created to provide access to the collected and processed data. This endpoint serves as the data source for the frontend components, enabling real-time access to system metrics, logs, and insights.

## 5. Frontend Development
The frontend is developed using TypeScript and Vite, providing an intuitive and responsive dashboard for visualizing system performance, model metrics, and optimization insights. The interface allows users to interact with the data and gain actionable insights for model enhancement.

## 6. Deployment
The entire application, including both backend and frontend components, is deployed as an Azure Web App using Azure App Service. This deployment ensures scalability, high availability, and ease of maintenance, allowing the system to efficiently handle increased traffic and interactions.

## Key Features
Comprehensive Model Monitoring: Visualizes important performance metrics such as precision, groundedness, F1 score, throughput, and latency.
User Feedback Integration: Collects and analyzes user feedback to evaluate its effect on model optimization.
Real-Time Data Insights: Provides actionable insights based on logs and metrics collected from the model for performance optimization.
Optimized Monitoring Tools: Uses Azure Monitor and Application Insights for continuous monitoring and in-depth analysis of system health.
Scalable Deployment: Deployed on Azure App Service, ensuring the solution scales with the growth of model usage and data.


## Future Enhancements
Advanced Feedback Features: Improve the system’s ability to process and use user feedback to further optimize model performance. We plan to integrate a component dedicated to clustering, categorizing and explain hallucinations sources and serve it to a intuitive User interface.
Enhanced Data Analytics: Expand the analysis capabilities to provide deeper insights into model optimization strategies.
Scalability Improvements: Increase system capacity for larger-scale AI deployments, ensuring smooth performance under heavy loads.
License

This project is licensed under the MIT License - see the LICENSE file for details.
